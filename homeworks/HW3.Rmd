---
title: "Homework 3"
output: html_document
author: "Daniil Rodionov, Hugo Aubert"
date: "2024-10-25"
---

```{r}
rm(list = ls())
```


List of the useful packages

```{r message=FALSE, warning=FALSE, include=FALSE}
suppressWarnings(suppressPackageStartupMessages(require(MASS)))
suppressWarnings(suppressPackageStartupMessages(require(MBA)))
suppressWarnings(suppressPackageStartupMessages(require(gstat)))
suppressWarnings(suppressPackageStartupMessages(require(sf)))
suppressWarnings(suppressPackageStartupMessages(require(geoR)))
suppressWarnings(suppressPackageStartupMessages(require(ggplot2)))
suppressWarnings(suppressPackageStartupMessages(require(corrplot)))
suppressWarnings(suppressPackageStartupMessages(require(dplyr)))
suppressWarnings(suppressPackageStartupMessages(require(sp)))
suppressWarnings(suppressPackageStartupMessages(require(RColorBrewer)))
```

```{r}
data(wolfcamp)
plot(wolfcamp)
summary(wolfcamp)
```
```{r}
# Define the directions in degrees
directions_deg <- c(0, 45, 90, 135)

# Convert directions to radians
directions_rad <- directions_deg * (pi / 180)

# Initialize an empty list to store the variogram results
variograms <- list()

# Loop over each direction in radians and compute the variogram
for (dir in directions_rad) {
  variograms[[paste("Direction", dir * (180 / pi))]] <- variog(wolfcamp, direction = dir)
}

# Plot each directional variogram in a combined plot
plot(variograms[[1]], type = "b", main = "Directional Variograms", col = "red",
     ylim = c(0, max(sapply(variograms, function(x) max(x$v)))))
for (i in 2:length(directions_rad)) {
  lines(variograms[[i]], type = "b", col = i)
}

legend("topleft", legend = paste("Direction", directions_deg, "degrees"), col = 1:length(directions_rad), lty = 1, bty = "n", adj = c(0, 0.5))



```


```{r bin-counts, message=FALSE, warning=FALSE}
# Calculate the omnidirectional variogram with a trend
variogram_result <- variog(wolfcamp, trend = "1st")

# Plot the bin counts for each distance class
plot(variogram_result$u, variogram_result$n, type = "b",
     main = "Number of Pairwise Comparisons per Bin (Omnidirectional, with Trend)",
     xlab = "distance", ylab = "count",
     col = "blue", pch = 16, lty = 1)

# Add grid lines for better readability
grid()

```



We can observe that the Variogram shows a linear relation between the Semi-Variance and the Distance until a distance = 250
we can suppose a stationnary model between the distance 0 and 250 so we can apply a trend = 1st and compare the variogram to
know model. 

```{r}
# Choose the Variogram model
vv <- variog(wolfcamp,trend = "1st", max.dist = 250)
plot(vv,type="b")
```


```{r}
#eyefit(vv) 
```


```{r}
plot(vv,type="b")

vv.exp <- likfit(wolfcamp,trend = "1st", cov.model = "exponential",ini.cov.pars = c(2000,100))
lines(vv.exp, col = "red")

vv.sph <- likfit(wolfcamp, trend = "1st", cov.model = "spherical", ini.cov.pars = c(2000,100))
lines(vv.sph, col = "blue")

vv.gau <- likfit(wolfcamp, trend = "1st", cov.model = "gaussian", ini.cov.pars = c(2000,100))
lines(vv.gau, col = "green")

legend("topleft", legend = c("Exponential", "Spherical", "Gaussian"), 
       col = c("red", "blue", "green"), lty = 1, bty = "n")
```
```{r}
# Spherical
vv.sph
summary(vv.sph)

# Exponential
vv.exp
summary(vv.exp)

# Gaussian
vv.gau
summary(vv.gau)
```
```{r}

logLik_exp <- summary_exp$likelihood$log.L
aic_exp <- summary_exp$likelihood$AIC
bic_exp <- summary_exp$likelihood$BIC

logLik_sph <- summary_sph$likelihood$log.L
aic_sph <- summary_sph$likelihood$AIC
bic_sph <- summary_sph$likelihood$BIC

logLik_gau <- summary_gau$likelihood$log.L
aic_gau <- summary_gau$likelihood$AIC
bic_gau <- summary_gau$likelihood$BIC


model_comparison <- data.frame(
  Model = c("Exponential", "Spherical", "Gaussian"),
  LogLikelihood = c(logLik_exp, logLik_sph, logLik_gau),
  AIC = c(aic_exp, aic_sph, aic_gau),
  BIC = c(bic_exp, bic_sph, bic_gau)
)


print(model_comparison)

```

According to the different summaries, we can observe that the exponential model fits the best with our variogram. Indeed, it has the highest maximized log-likelihood value (-454.9), along with the lowest AIC (927.9) and BIC (949.8), indicating the best balance between fit accuracy and model complexity. Additionally, the exponential model’s parameters suggest a tighter spatial correlation, with a smaller range parameter (phi = 21.23) and a relatively low nugget effect (519.8), making it particularly suitable for capturing the spatial dependencies within our dataset.


```{r}
# Run cross-validation and calculate the cross-validation coefficient for each model
xvalid_exp <- xvalid(wolfcamp, model = vv.exp)
xvalid_sph <- xvalid(wolfcamp, model = vv.sph)
xvalid_gau <- xvalid(wolfcamp, model = vv.gau)

# Calculate the cross-validation coefficient (mean of squared standardized errors)
cv_coefficient_exp <- mean(xvalid_exp$std.error^2)
cv_coefficient_sph <- mean(xvalid_sph$std.error^2)
cv_coefficient_gau <- mean(xvalid_gau$std.error^2)

# Combine results into a data frame for comparison
xvalid_comparison <- data.frame(
  Model = c("Exponential", "Spherical", "Gaussian"),
  CrossValidationCoefficient = c(cv_coefficient_exp, cv_coefficient_sph, cv_coefficient_gau)
)

# Display the results
print(xvalid_comparison)

```



```{r}
mse_exp <- mse_sph <- mse_gau <- numeric(nrow(wolfcamp$coords))

# Boucle pour la validation croisée leave-one-out
for (i in 1:nrow(wolfcamp$coords)) {
    # Retrait du point i pour créer un ensemble de données LOO
    loo_coords <- wolfcamp$coords[-i, ]
    loo_data <- wolfcamp$data[-i]
    loo_wolfcamp <- as.geodata(data.frame(coords = loo_coords, data = loo_data))
    
    # Ajustement de chaque modèle sur les données LOO
    fit_exp <- likfit(loo_wolfcamp, trend = "1st", cov.model = "exponential", ini.cov.pars = c(2000,100))
    fit_sph <- likfit(loo_wolfcamp, trend = "1st", cov.model = "spherical", ini.cov.pars = c(2000,100))
    fit_gau <- likfit(loo_wolfcamp, trend = "1st", cov.model = "gaussian", ini.cov.pars = c(2000,100))
    
    # Prédiction pour le point retiré
    pred_exp <- krige.conv(geodata = loo_wolfcamp, locations = wolfcamp$coords[i, , drop = FALSE], krige = krige.control(obj.model = fit_exp))$predict
    pred_sph <- krige.conv(geodata = loo_wolfcamp, locations = wolfcamp$coords[i, , drop = FALSE], krige = krige.control(obj.model = fit_sph))$predict
    pred_gau <- krige.conv(geodata = loo_wolfcamp, locations = wolfcamp$coords[i, , drop = FALSE], krige = krige.control(obj.model = fit_gau))$predict
    
    # Calcul de l'erreur quadratique pour le point i
    mse_exp[i] <- sqrt((wolfcamp$data[i] - pred_exp)^2)
    mse_sph[i] <- sqrt((wolfcamp$data[i] - pred_sph)^2)
    mse_gau[i] <- sqrt((wolfcamp$data[i] - pred_gau)^2)
}

# Calcul de la MSE moyenne pour chaque modèle
mean_mse_exp <- mean(mse_exp)
mean_mse_sph <- mean(mse_sph)
mean_mse_gau <- mean(mse_gau)
```

```{r}
# Résultats
cat("Exponential MSE moyenne:", mean_mse_exp, "\n")
cat("Spherical MSE moyenne:", mean_mse_sph, "\n")
cat("Gaussian MSE moyenne:", mean_mse_gau, "\n")
```

Moreover, the RMSE of our exponential model is a little bit more than the Spherical and Gaussian model but not far from their value. 

Question 2

```{r}
grid <- expand.grid(
  x = seq(min(wolfcamp$coords[,1]), max(wolfcamp$coords[,1])),
  y = seq(min(wolfcamp$coords[,2]), max(wolfcamp$coords[,2]))
)

kriging_result_sph <- krige.conv(wolfcamp, 
                             locations = grid, 
                             krige = krige.control(obj.model = vv.sph))
image(kriging_result_sph, main = "Kriging Interpolation (Spherical Model)")
points(wolfcamp$coords, col = "red", pch = 16)

kriging_result_gau <- krige.conv(wolfcamp, 
                             locations = grid, 
                             krige = krige.control(obj.model = vv.gau))
image(kriging_result_gau, main = "Kriging Interpolation (Gaussian Model)")
points(wolfcamp$coords, col = "red", pch = 16)

kriging_result_exp <- krige.conv(wolfcamp, 
                             locations = grid, 
                             krige = krige.control(obj.model = vv.exp))
image(kriging_result_exp, main = "Kriging Interpolation (Exponential Model)")
points(wolfcamp$coords, col = "red", pch = 16)

```
```{r}
# Préparation des variables pour stocker les erreurs
errors_sph <- numeric(nrow(wolfcamp$coords))
errors_gau <- numeric(nrow(wolfcamp$coords))
errors_exp <- numeric(nrow(wolfcamp$coords))

# Boucle de validation croisée leave-one-out
for (i in 1:nrow(wolfcamp$coords)) {
  
  # Créer des sous-ensembles sans le point "i"
  coords_loo <- wolfcamp$coords[-i, , drop = FALSE]
  data_loo <- wolfcamp$data[-i]
  
  # Krigeage sur les données restantes sans le point "i"
  kriging_result_sph <- krige.conv(geodata = list(coords = coords_loo, data = data_loo), 
                                   locations = wolfcamp$coords[i, , drop = FALSE],
                                   krige = krige.control(obj.model = vv.sph))
  
  kriging_result_gau <- krige.conv(geodata = list(coords = coords_loo, data = data_loo), 
                                   locations = wolfcamp$coords[i, , drop = FALSE],
                                   krige = krige.control(obj.model = vv.gau))
  
  kriging_result_exp <- krige.conv(geodata = list(coords = coords_loo, data = data_loo), 
                                   locations = wolfcamp$coords[i, , drop = FALSE],
                                   krige = krige.control(obj.model = vv.exp))
  
  # Calculer les erreurs de prédiction pour chaque modèle
  errors_sph[i] <- wolfcamp$data[i] - kriging_result_sph$predict
  errors_gau[i] <- wolfcamp$data[i] - kriging_result_gau$predict
  errors_exp[i] <- wolfcamp$data[i] - kriging_result_exp$predict
}

```

```{r}
# Calcul du RMSE pour chaque modèle
rmse_sph <- sqrt(mean(errors_sph^2))
cat("RMSE Modèle Sphérique (LOOCV):", rmse_sph, "\n")

rmse_gau <- sqrt(mean(errors_gau^2))
cat("RMSE Modèle Gaussien (LOOCV):", rmse_gau, "\n")

rmse_exp <- sqrt(mean(errors_exp^2))
cat("RMSE Modèle Exponentiel (LOOCV):", rmse_exp, "\n")
```
